---
title: Several GANs
tags: GAN
show_author_profile: true
mathjax: true
excerpt_separator: <!--more-->
article_header:
  type: cover
  image:
    src: /assets/images/background/dragon.jpg
---

摘要：

此文摘录了一些现阶段常见的GAN网络理论及相关改进。大致分为如下两个部分：一、GANs的理论提升；二、GANs的应用。

<!--more-->

详细正文：                                           

Part1 GANs基于Div的改进

1）JS距离的偏差问题

产生这个问题的原因在于，GAN网络在训练判别器的过程中，最大化$$V=E_{x \sim P_data}$$

目前主流的迁移学习的问题背景都是：源域和目标域的特征空间与类别空间一致，只是数据的分布不一致，如何进行迁移。也就是说，源域和目标域要是几类，都是几类。

但这种情况显然具有很大的局限性：在真实应用中，我们往往不知道目标域的类别，更无法得知它是否和源域的类别完全一致，这极大的限制了迁移学习在真实中的应用。

迁移学习的目标就是利用大量有标注的源数据对目标数据进行建模。如果我们用$$Y_s$$和$$Y_t$$分别表示源域和目标域的类别空间，那么部分迁移学习就是$$Y_s \supset Y_t$$，这种情况比通常意义下的迁移学习更有挑战性。

作者的思想很直接，如果源域类别与目标域多的情况下无法进行迁移，那么我们就先选择出源域中与目标域那部分最接近的样本，给它们赋予高权重，然后再进行迁移。

基于这个想法，作者设计了一个两阶段的深度对抗网络。我们都知道对抗网络主要由特征提取器（feature extractor）和领域分类器（domain classifier）组成。前者用于提取样本的公共特征，后者用于鉴别两领域是否相似。

已有工作通常会对源域和目标域采用一个公共的特征提取器。但是在部分迁移学习中，源域和目标域的类别往往不同，因此作者提出对它们分别采用不同的特征提取器进行。这样做还有一个好处就是，不同的特征提取器可以针对各自的 domain 学习到各自的表征性特征。 

在学习时，固定源域的特征提取器不变，只学习目标域的特征，这更符合原始GAN的理论。

![Image](/assets/images/papers/WAN.png){:.border}

作者提出了一个深度加权对抗网络（Importance Weighted Adversarial Nets），网络的示意图如上。

网络的主要部分为：分别作用于源域和目标域的两个特征提取器（图中的$$F_s$$和$$F_t$$），以及两个领域分类器（图中的$$D$$和$$D_0$$）。第一个领域分类器用来筛选出源域中与目标域相似的那部分（或者源域中与目标领域共享的那部分类别），第二个领域分类器进行正常的Domain Adaptation。

相应的，方法主要分为两个部分：1）筛选出源域中与目标域属于相同类别的样本，2）综合学习。

样本筛选：

此部分是该论文的核心创新点。主要思路：由$$F_s$$和$$F_t$$产生的源域特征$$Z_s$$，目标域特征$$Z_t$$，并通过一个领域分类器$$D$$，判别样本是来自源域还是目标域。

这个$$D$$是一个二分类器，这里面有一个问题，就是如何才能知道样本是属于源域和目标域的公共类别，而不是特异于源域的类别（作者称这类样本为outlier）。

如果$$D(z) \in 1$$，则表示$$z$$这样本来自源域。更进一步分析，为什么这部分样本只是来自源域，因为这部分样本是源域独有的，否则，它就同样来自目标域了。

从另一个角度来说，如果$$D(z) \in 0$$，则表示这部分样本来自目标域，但同时，它也可能来自源域与目标域共享的类别。

就这个简单而直观的道理指导着我们设计不同的权重。我们的目标是，对于筛选出的那部分与目标域属于相同类别的源域样本，我们赋予它们大权重，另一部分源域特有的样本，赋予小权重。该权重可被表示为：

$$w(z)=1-D^\star(z)=\cfrac {1}{1+\cfrac {p_s(z)}{p_t(z)}}$$

这里的$$D^\star$$表示的是领域分类器$$D$$的最优值，它可以通过求导得出：

$$D^\star=\frac{p_s(z)}{P_s(z)+p_t(z)}$$

从这个式子可以看出，如果$$D^\star(z)$$值较大，则表示样本更可能是outlier，那么权重值就会变小；反之，如果$$D^\star(z)$$值较小，则表示样本更可能是源域和目标域的共同部分，那么权重就会变大。这个方法很好地对源和目标域中的共同类别的样本完成了筛选工作。

作者还对源域部分的权重进行了归一化，从而更加明确样本的从属关系。下一步工作是处理领域分类器$$D_0$$，$$D_0$$也可以以同样的求导方式得到。

在训练网络之前，作者还加了一个熵最小化项用于对目标域的样本属性进行约束，这也是比较常见的做法。于是GAN网络的学习目标就变为了：

![Image](/assets/images/papers/GAN-AD.png){:.border}

实验：

实验选取的数据集是Office-Caltech 以及 Office-31。不过实验任务与之前的迁移学习有所不同：源域的类别比目标域多。

作者和一些最新的迁移学习方法进行了对比，表明了所提方法的优势。

作者还特别做了一个实验：当目标域的类别个数逐渐变多时，精度如何变化？结论是，随着目标域类别个数的减少，精度逐渐增加。这表明知识在进行迁移时，源域知识越多，通过筛选，对目标越有效。